# WARP.md

Development guidance for PyContextify - a Python MCP server for semantic search with lightweight knowledge graph capabilities.

## Setup

```bash
# Install UV and dependencies
curl -LsSf https://astral.sh/uv/install.sh | sh
uv sync --extra dev
```

## Essential Commands

```bash
# Run server
uv run pycontextify --verbose

# Run tests with coverage
uv run pytest --cov=pycontextify

# Code quality
uv run black . && uv run isort . && uv run flake8
uv run mypy pycontextify

# Dependency management
uv add package-name              # Runtime
uv add --dev package-name        # Development
uv sync --reinstall              # Reset environment

# Packaging & release validation
python scripts/build_package.py   # Build wheel/sdist + twine check
```

## Release Workflow

1. Update the project version in `pyproject.toml` and document the changes in `CHANGELOG.md`
2. Run `uv sync --extra dev` to install packaging helpers (`build`, `twine`)
3. Execute `python scripts/build_package.py` to produce `dist/` artifacts and validate metadata
4. Upload to TestPyPI/PyPI with `twine upload dist/*`
5. Tag the release and push (`git tag vX.Y.Z && git push --tags`)

## Architecture

### Key Components
- **IndexManager**: Central coordinator with pre-loaded embedders (`manager.py`)
- **VectorStore**: FAISS wrapper with persistence (`vector_store.py`)
- **EmbedderFactory**: Provider system (`embedders/factory.py`) — currently ships with the sentence-transformers implementation and validation stubs for future providers
- **HybridSearchEngine**: Vector + keyword search (`hybrid_search.py`)
- **Content Chunkers**: Code/document-aware processing (`chunker.py`)
- **Relationship Extraction**: Lightweight knowledge graph integrated into `chunker.py` and `models.py`

### Pipeline: Load → Chunk → Embed → Store → Search

## Chunking Strategies by Resource Type

- **Code files** → `CodeChunker`
  - Detects natural boundaries using function/class signatures and visibility keywords before falling back to token windows, ensuring structural cohesion for languages such as Python, JS/TS, Java, C-family, and Go.
  - Captures relationships like function/class names, imports, and simple variable declarations to enrich the lightweight knowledge graph for downstream search.

- **Documents (Markdown/Text/PDF)** → `DocumentChunker`
  - Breaks content along Markdown-style headers while enforcing minimum section length, with token-based fallback for unstructured prose.
  - Extracts contextual relationships from links, citations, emphasized terms, and section titles; PDF files are first converted to text via `DocumentLoader`/`PDFLoader` and then treated like other documents.

- **Fallback/Unknown sources** → `SimpleChunker`
  - Applies configurable token windows with overlap and basic capitalized-entity extraction when the source type is not recognized or lacks structure.

`IndexManager` selects the appropriate strategy at runtime through `ChunkerFactory`, and all chunkers honor the shared configuration for chunk size, overlap, and relationship extraction limits defined in `Config`.

### Search Methods
- **Vector**: FAISS IndexFlatIP (cosine similarity)
- **Keyword**: TF-IDF + BM25 with configurable weighting
- **Reranking**: Not currently implemented (placeholders remain in models for future cross-encoder support)

## MCP Interface

5 essential functions:
1. `index_filebase(path, tags)` - Unified code/document indexing with relationship extraction
2. `discover()` - List indexed tags to aid navigation
3. `search(query, top_k=5)` - Hybrid semantic + keyword search
4. `reset_index(remove_files=True, confirm=False)` - Clear index data
5. `status()` - System statistics

### Search Result JSON Outline

**IndexManager API (`IndexManager.search`)**
- Returns a `SearchResponse` object with a consistent envelope: `success`, `query`, `search_config`, `results`, `total_results`, and optional `performance` / `query_analysis` data. Each `SearchResult` includes `text`, `relevance_score`, a structured `scores` dictionary (vector/keyword/combined), optional `position`, `metadata`, and provenance fields.
- Calling `SearchResponse.to_dict()` or using `display_format="structured"` yields a deterministic JSON object—ideal for integrations that use the Python package directly.

**MCP `search` tool (default `display_format="structured"`)**
- Returns a simplified list of dictionaries for tool consumers. Each item includes:
  - `chunk_id`
  - `chunk_text`
  - `similarity_score`
  - `source_path`
  - `source_type`
  - `metadata` (structured when available)
  - `scores` (keys such as `vector`, `keyword`, `combined`, depending on search mode)
- On error (validation failure, empty index, etc.) the structured format falls back to an empty list. Readable/summary formats return formatted strings generated by `SearchResponse.format_for_display()`.

**Notes**
- Hybrid search enriches `scores` with both semantic and keyword contributions. Reranking support was removed to simplify the code paths, so only vector and keyword signals remain.
- Relationship context is not injected into search results yet; see “Knowledge Graph” below for access patterns.

## Configuration

**Priority**: CLI args > Environment variables > Defaults

### Key Settings
- `PYCONTEXTIFY_EMBEDDING_PROVIDER`: sentence_transformers (default)
- `PYCONTEXTIFY_EMBEDDING_MODEL`: all-MiniLM-L6-v2 (default)
- `PYCONTEXTIFY_AUTO_PERSIST`: true (default)
- `PYCONTEXTIFY_INDEX_DIR`: ./index_data (default)
- `PYCONTEXTIFY_CHUNK_SIZE`: 512 (default)

## Knowledge Graph

**Lightweight approach** - no external database required

**Relationship signals extracted today**
- **Tags**: `import`, markdown section names, `citation`, domains, URL path fragments, `external_link`, `contact`
- **References**: Proper nouns, markdown links, citations, URLs, email addresses, detected code symbols
- **Code symbols**: Function, class, and variable names identified by the chunkers

**Access**
- Relationship data lives on each `ChunkMetadata` instance (`tags`, `references`, `code_symbols`). It is not yet surfaced automatically in MCP search responses.
- Retrieve relationship details via `IndexManager.metadata_store` or by extending the search result formatting to include `ChunkMetadata.get_relationships()`.

## Testing

**247 tests, 69% coverage - 100% pass rate**
- Core components: 85-87% coverage
- Run: `uv run pytest --cov=pycontextify`
- MCP test runner: `uv run python scripts/run_mcp_tests.py`
- Quick smoke test: `uv run python scripts/run_mcp_tests.py --smoke`
- Consolidated test files: 15 test files
- All persistence tests passing after auto-load fixes

## File Support

**Code**: Python, JS/TS, Java, C/C++, Rust, Go, etc.  
**Documents**: PDF (PyPDF2/pdfplumber), Markdown, Text  

## Performance

**Models**:
- `all-MiniLM-L6-v2`: Fast, 384D
- `all-mpnet-base-v2`: Better quality, 768D

**Scaling**: Memory scales with corpus size. Use IndexIVFFlat for >100k chunks.

## Scripts

**Available utilities**:
- `python scripts/run_mcp_tests.py` - MCP test runner with coverage
- `python scripts/build_package.py` - Build distribution packages

## Troubleshooting

**Model loading**: Ensure internet for first download
**Memory issues**: Use `all-MiniLM-L6-v2` model
**Dependencies**: `uv sync --reinstall`
**Permissions**: Check index directory write access
**Debug**: Use `--verbose` flag for detailed logging
**Windows**: Set `$env:PYTHONPATH = "."` before running scripts

## File-Level Summary

### Markdown Documentation
- **README.md** – Provides project overview, setup, configuration guidance, and API usage instructions.
- **WARP.md** – Acts as a developer handbook covering environment setup, architecture, MCP interface, configuration priorities, and troubleshooting tips.
- **PRD.md** – Captures product requirements, user stories, functional scope, and success metrics for the platform.
- **scripts/README.md** – Catalogs available utility scripts, their purposes, and execution notes.

### Python Sources
- **pycontextify/__init__.py** – Exposes the package’s primary configuration and indexing interfaces for external consumers.
- **pycontextify/config.py** – Loads, validates, and summarizes configuration for indexing, chunking, embeddings, and persistence.
- **pycontextify/embedder.py / embedder_factory.py** – Host the embedding abstractions, provider implementations, and factory wiring.
- **pycontextify/chunker.py** – Provides base and specialized chunkers for code and documents, handling splitting and metadata extraction.
- **pycontextify/storage_metadata.py** – Defines source types, chunk metadata, and persistent metadata storage for the knowledge graph.
- **pycontextify/storage_vector.py** – Wraps FAISS vector storage operations, including persistence, backup, and validation routines.
- **pycontextify/search_hybrid.py** – Implements keyword-based hybrid search that complements vector similarity results.
- **pycontextify/search_models.py** – Defines search-related data structures, response formatting helpers, and analytics utilities.
- **pycontextify/indexer.py** – Coordinates indexing, search execution, persistence, and lifecycle management for the entire system.
- **pycontextify/loader.py** – Supplies loaders for documents and codebases, orchestrating ingestion workflows per source type.
- **pycontextify/mcp.py** – Exposes MCP server tooling, validation helpers, and CLI entry points for indexing and searching.
- **scripts/run_mcp_tests.py** – Runs comprehensive or smoke MCP test suites and reports results.
- **scripts/build_package.py** – Builds wheel and source distributions with metadata validation.

## Design Decisions

**UV**: Fast dependency management, lockfiles, optional dependencies  
**FAISS**: High-performance vector search with CPU/GPU support  
**Pre-loaded Models**: Embedders initialize at startup for fast first requests  
**Simplified MCP**: 5 essential functions, clean and focused API
**No External DB**: File-based persistence, lightweight knowledge graph
