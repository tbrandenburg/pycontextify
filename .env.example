# PyContextify MCP Server Configuration
# Copy this file to .env and customize as needed

# Index Storage Configuration
PYCONTEXTIFY_INDEX_DIR=./index_data
PYCONTEXTIFY_INDEX_NAME=semantic_index

# Persistence Settings
PYCONTEXTIFY_AUTO_PERSIST=true
PYCONTEXTIFY_AUTO_LOAD=true
PYCONTEXTIFY_COMPRESS_METADATA=true
PYCONTEXTIFY_BACKUP_INDICES=false
PYCONTEXTIFY_MAX_BACKUPS=3

# Embedding Provider Configuration
# Options: sentence_transformers, ollama, openai
PYCONTEXTIFY_EMBEDDING_PROVIDER=sentence_transformers

# Sentence Transformers Settings (default provider)
PYCONTEXTIFY_EMBEDDING_MODEL=all-mpnet-base-v2
# Alternative models: all-MiniLM-L6-v2, all-distilroberta-v1, multi-qa-mpnet-base-dot-v1

# Ollama Settings (for future use)
# PYCONTEXTIFY_EMBEDDING_PROVIDER=ollama
# PYCONTEXTIFY_EMBEDDING_MODEL=nomic-embed-text
# PYCONTEXTIFY_OLLAMA_BASE_URL=http://localhost:11434

# OpenAI Settings (for future use)
# PYCONTEXTIFY_EMBEDDING_PROVIDER=openai
# PYCONTEXTIFY_EMBEDDING_MODEL=text-embedding-3-small
# PYCONTEXTIFY_OPENAI_API_KEY=your_api_key_here

# Text Chunking Configuration
PYCONTEXTIFY_CHUNK_SIZE=512
PYCONTEXTIFY_CHUNK_OVERLAP=50

# Lightweight Knowledge Graph Settings
PYCONTEXTIFY_ENABLE_RELATIONSHIPS=true
PYCONTEXTIFY_MAX_RELATIONSHIPS_PER_CHUNK=10

# Advanced Search Settings
PYCONTEXTIFY_USE_HYBRID_SEARCH=true
PYCONTEXTIFY_USE_RERANKING=true
PYCONTEXTIFY_KEYWORD_WEIGHT=0.3
PYCONTEXTIFY_RERANKING_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# PDF Processing Settings
PYCONTEXTIFY_PDF_ENGINE=pymupdf  # Options: pymupdf, pypdf2, pdfplumber

# Performance Settings (Optional)
# PYCONTEXTIFY_MAX_FILE_SIZE_MB=10
# PYCONTEXTIFY_BATCH_SIZE=32
# PYCONTEXTIFY_CRAWL_DELAY_SECONDS=1